{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: <utf-8> -*-\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import unidecode\n",
    "import csv \n",
    "import io\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"where's all the ron paul trolls, to defend thispiece of shit?\"\"\"\n",
      "\n",
      "n_samples : 4415\n"
     ]
    }
   ],
   "source": [
    "train_fname = 'train.csv'\n",
    "test_fname = 'test.csv'\n",
    "X = []\n",
    "y = []\n",
    "test = []\n",
    "with io.open(train_fname, encoding = 'utf-8') as f:\n",
    "     for line in f: \n",
    "        line = line.replace(\"\\\\xa0\", \"\")\n",
    "        line = line.replace(\"\\\\n\", \"\")\n",
    "        line = line.lower()\n",
    "        y.append(int(line[0]))\n",
    "        X.append(line[5:-6])\n",
    "y = np.array(y)\n",
    "\n",
    "with io.open(test_fname, encoding = 'utf-8') as f:\n",
    "     for line in f: \n",
    "        line = line.replace(\"\\\\xa0\", \"\")\n",
    "        line = line.replace(\"\\\\n\", \"\")\n",
    "        line = line.lower()\n",
    "        # y.append(int(line[0]))\n",
    "        test.append(line)\n",
    "# y = np.array(y)\n",
    "print test[0]\n",
    "print('n_samples : %d' % len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le taux de prédiction au niveau de la chance est : 0.694450736127\n"
     ]
    }
   ],
   "source": [
    "print(\"Le taux de prédiction au niveau de la chance est : %s\" % np.mean(y == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4415, 16821)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X)\n",
    "X_test_counts = count_vect.transform(test)\n",
    "print X_train_counts.shape\n",
    "count_vect.vocabulary_.get(u'fuck')\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_test_tf = tf_transformer.transform(X_test_counts)\n",
    "\n",
    "# This dataset is way to high-dimensional. Better do PCA:\n",
    "pca = PCA(n_components=1000)\n",
    "\n",
    "# Maybe some original features where good, too?\n",
    "selection = SelectKBest(k=500)\n",
    "\n",
    "combined_features = FeatureUnion([(\"pca\", pca), (\"univ_select\", selection)])\n",
    "# combined_features = FeatureUnion([(\"pca\", pca)])\n",
    "\n",
    "# Use combined features to transform dataset:\n",
    "X_features = combined_features.fit(X_train_tf.toarray(), y).transform(X_train_tf.toarray())\n",
    "test_features = combined_features.transform(X_test_tf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear', gamma=2)\n",
    "clf.fit(X_features, y)\n",
    "y_pre = clf.predict(test_features)\n",
    "np.savetxt('y_pred.txt', y_pre, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel :  linear\n",
      "[ 0.80095109  0.80163043  0.82053025]\n",
      "kernel :  poly\n",
      "[ 0.77853261  0.77717391  0.77090415]\n",
      "kernel :  rbf\n",
      "[ 0.7826087   0.77853261  0.76954453]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "for kernel in ('linear', 'poly', 'rbf'):\n",
    "    clf = SVC(kernel=kernel, gamma=2)\n",
    "# clf = SVC()\n",
    "    print \"kernel : \", kernel\n",
    "    print cross_val_score(clf, X_features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordContent = []\n",
    "wordCount = dict()\n",
    "import re\n",
    "regEx = re.compile('\\\\W*') # match any ~[A-Z0-9]\n",
    "for x in X:\n",
    "    for word in regEx.split(x):\n",
    "        if word in wordCount.keys():\n",
    "            wordCount[word] = wordCount[word] + 1\n",
    "        else:\n",
    "            wordCount[word] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'all', u\"she'll\", u\"don't\", u'being', u'over', u'through', u'yourselves', u'its', u'before', u\"he's\", u\"when's\", u\"we've\", u'had', u'should', u\"he'd\", u'to', u'only', u\"there's\", u'those', u'under', u'has', u\"haven't\", u'do', u'them', u'his', u\"they'll\", u'very', u\"who's\", u\"they'd\", u'cannot', u\"you've\", u'they', u'not', u'during', u'yourself', u'him', u'nor', u\"we'll\", u'did', u\"they've\", u'this', u'she', u'each', u\"won't\", u'where', u\"mustn't\", u\"isn't\", u\"i'll\", u\"why's\", u'because', u\"you'd\", u'doing', u'some', u'up', u'are', u'further', u'out', u'what', u'for', u'while', u\"wasn't\", u'does', u\"shouldn't\", u'above', u'between', u'be', u'we', u'who', u\"you're\", u'were', u'here', u'hers', u\"aren't\", u'by', u'both', u'about', u'would', u'of', u'could', u'against', u\"i'd\", u\"weren't\", u\"i'm\", u'or', u\"can't\", u'own', u'into', u'whom', u'down', u\"hadn't\", u\"couldn't\", u'your', u\"doesn't\", u'from', u\"how's\", u'her', u'their', u\"it's\", u'there', u'been', u'why', u'few', u'too', u'themselves', u'was', u'until', u'more', u'himself', u\"where's\", u\"i've\", u'with', u\"didn't\", u\"what's\", u'but', u'ours\\tourselves', u'herself', u'than', u\"here's\", u'he', u'me', u\"they're\", u'myself', u'these', u\"hasn't\", u'below', u'ought', u'theirs', u'my', u\"wouldn't\", u\"we'd\", u'and', u'then', u'is', u'am', u'it', u'an', u'as', u'itself', u'at', u'have', u'in', u'any', u'if', u'again', u'no', u'that', u'when', u'same', u'how', u'other', u'which', u'you', u\"shan't\", u'our', u'after', u\"let's\", u'most', u'such', u'on', u\"he'll\", u'a', u'off', u'i', u\"she'd\", u'yours', u\"you'll\", u'so', u\"we're\", u\"she's\", u'the', u\"that's\", u'having', u'once'])\n"
     ]
    }
   ],
   "source": [
    "stopList = set()\n",
    "with io.open('stop_word.txt', newline = '\\n') as f:\n",
    "     for line in f: \n",
    "        line = line.strip()\n",
    "        stopList.add(line)\n",
    "print stopList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filtre(wordCount, cirtere, stopList):\n",
    "    wordList = []\n",
    "    for key, value in wordCount.iteritems():\n",
    "        if key not in stopList and value > cirtere:\n",
    "            wordList.append(key)\n",
    "    return wordList\n",
    "            \n",
    "        \n",
    "    \n",
    "def words2Vectors(wordList, data):\n",
    "    vec = [0] * len(wordList)\n",
    "    for word in data:\n",
    "        if word in wordList:\n",
    "            vec[wordList.index(word)] = vec[wordList.index(word)] + 1 // +1\n",
    "    return vec\n",
    "\n",
    "def createWordList(wordContent):\n",
    "    # no word occur twice\n",
    "    wordSet = set()\n",
    "    for word in wordContent:\n",
    "        if word not in wordSet:\n",
    "            wordSet.add(word)\n",
    "    return list(wordSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordList  = createWordList(wordContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f45f889abbfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords2Vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-c132c6561319>\u001b[0m in \u001b[0;36mwords2Vectors\u001b[0;34m(wordList, data)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwordList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwordList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwordList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wordList = filtre(wordCount, 2, stopList)\n",
    "vectors = []\n",
    "for x in X:\n",
    "    vectors.append(words2Vectors(wordList, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('vectors.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print wordList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
