{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention\n",
    "#### Il faut installer enchant pour corriger des mots\n",
    "#### istaller nltk et aussi ajouer un wordnet en lancant  nltk.download()\n",
    "#### aussi j'ai remplace le ficher de stopswords par un autre version plus complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: <utf-8> -*-\n",
    "## pip install pyenchant, ntlk\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import unidecode\n",
    "import csv \n",
    "import io\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import bigrams\n",
    "from nltk.stem.snowball import EnglishStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readdata(filename):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    with io.open(train_fname, encoding = 'utf-8') as f:\n",
    "        for line in f:\n",
    "            y.append(line[0])\n",
    "            X.append(line[5:])\n",
    "    return y,X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def repeatreplace(word):\n",
    "    if wordnet.synsets(word):\n",
    "        return word\n",
    "    repl_word=re.compile(r'(\\w*)(\\w)\\2(\\w*)').sub(r'\\1\\2\\3',word)\n",
    "    if repl_word!=word:\n",
    "        return replace(repl_word)\n",
    "    else:\n",
    "        return repl_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def repeatreplace(tokenList):\n",
    "    for i in range(len(tokenList)): \n",
    "        word=tokenList[i]\n",
    "        repl_word=re.compile(r'(\\w*)(\\w)\\2(\\w*)').sub(r'\\1\\2\\3',word)\n",
    "        if wordnet.synsets(word):\n",
    "            word=word\n",
    "        elif repl_word!=word:\n",
    "            word=replace(repl_word)\n",
    "        else:\n",
    "            word=repl_word\n",
    "        tokenList[i]=word\n",
    "    return tokenList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def removehtmltags(line):    \n",
    "    p=re.compile(r\"<.*?>\")\n",
    "    line = p.sub(' ', line)\n",
    "    line = line.replace('&nbsp;',' ')   \n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removebadtoken(line):\n",
    "    rep = {'\\\\xa0': ' ', '\\\\xc2': ' ', '\\\\n': ' ', '\\r': ''}\n",
    "    rep = dict((re.escape(k), v) for k, v in rep.items())\n",
    "    pattern = re.compile(\"|\".join(rep.keys()))\n",
    "    line = pattern.sub(lambda m: rep[re.escape(m.group(0))], line)\n",
    "    return line   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Tokenization(line):\n",
    "    line=line.lower()\n",
    "    tokenlist = wordpunct_tokenize(line)\n",
    "    return tokenlist    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removestopwords(tokenList):\n",
    "    stopwordList=np.genfromtxt('/Users/cristalezx/Desktop/SD_207_challenge/Insulting-Comment-Detection-master/stopwords.txt',dtype='str')\n",
    "    filteredWords = [w for w in tokenList if not w in stopwordList]\n",
    "    return filteredWords    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def commentnormalizer(line):\n",
    "    line = \"\".join([ch for ch in line if ch not in string.punctuation])\n",
    "    line = re.sub(\"\\\\d+(\\\\.\\\\d+)?\", \"NUM\", line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def commentStemmer(tokenList):\n",
    "    stemmer = EnglishStemmer()\n",
    "    for i in range(len(tokenList)):\n",
    "        tokenList[i] = stemmer.stem(tokenList[i])\n",
    "    return tokenList "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import enchant\n",
    "from nltk.metrics import edit_distance\n",
    "def commentcorrect(tokenList):\n",
    "    dict_name=\"en\"\n",
    "    spell_dict=enchant.Dict(dict_name)\n",
    "    max_dist=2\n",
    "    for i in range(0,len(tokenList)):\n",
    "        if spell_dict.check(tokenList[i]):\n",
    "            tokenList[i]=tokenList[i]\n",
    "        else:\n",
    "            suggestions=spell_dict.suggest(tokenList[i])\n",
    "            if suggestions and edit_distance(tokenList[i],suggestions[0])<=max_dist:\n",
    "                tokenList[i]=suggestions[0]\n",
    "            else:\n",
    "                tokenList[i]=tokenList[i]\n",
    "    return tokenList        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shit', 'language']"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentcorrect([\"sh?t\",\"languege\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## badwords in the bad words list\n",
    "def encountebadwords(tokenList):  \n",
    "    \n",
    "    badList = []\n",
    "    with io.open('/Users/cristalezx/Desktop/SD_207_challenge/Insulting-Comment-Detection-master/badwords.txt', newline = '\\n') as f:\n",
    "         for line in f:     \n",
    "            badList.append(line[:len(line)-1])\n",
    "    badList=commentcorrect(badList)\n",
    "    badList=repeatreplace(badList)\n",
    "    c=0\n",
    "    for w in badList:\n",
    "        if wordnet.synsets(w):\n",
    "            print \"true\",w\n",
    "            c=c+1 \n",
    "            \n",
    "            \n",
    "        else:\n",
    "            print w\n",
    "    print c\n",
    "    print len(badList)\n",
    "    count=0\n",
    "    for w in tokenList:\n",
    "        if w in badList:\n",
    "            count=count+1\n",
    "    return  count  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true hole\n",
      "true anus\n",
      "ash0le\n",
      "ash0les\n",
      "as holes\n",
      "true ass\n",
      "As Monkey\n",
      "As face\n",
      "ash0le\n",
      "ash0lez\n",
      "as hole\n",
      "as holes\n",
      "asholz\n",
      "as swipe\n",
      "true armhole\n",
      "basterds\n",
      "true bastard\n",
      "true bastards\n",
      "true bastard\n",
      "true bastards\n",
      "true bastardy\n",
      "true Batch\n",
      "true bitch\n",
      "true bitches\n",
      "Blow Job\n",
      "true offing\n",
      "but thole\n",
      "but wipe\n",
      "true cock\n",
      "true cocks\n",
      "ck\n",
      "Carpet Muncher\n",
      "true caw\n",
      "true caws\n",
      "true Lit\n",
      "true cents\n",
      "true chintz\n",
      "true cock\n",
      "cock head\n",
      "cock-head\n",
      "true cocks\n",
      "Cock Sucker\n",
      "true cocksucker\n",
      "true crap\n",
      "true cum\n",
      "true cut\n",
      "true cuts\n",
      "cuntz\n",
      "true dick\n",
      "true dildo\n",
      "true dildos\n",
      "true dildo\n",
      "true dildos\n",
      "dild0\n",
      "dild0s\n",
      "dominatricks\n",
      "true dominatrix\n",
      "true dominatrix\n",
      "true dyke\n",
      "true enema\n",
      "f u c k\n",
      "f u c k e r\n",
      "true fag\n",
      "true faggot\n",
      "true facet\n",
      "true faggot\n",
      "true faggot\n",
      "true faggot\n",
      "fait\n",
      "true fags\n",
      "true fag\n",
      "true fig\n",
      "true figs\n",
      "true fart\n",
      "fliping the bird\n",
      "true fuck\n",
      "true fucker\n",
      "true fucking\n",
      "true fucking\n",
      "true fucks\n",
      "Fudge Packer\n",
      "true funk\n",
      "Fukah\n",
      "Fuken\n",
      "true fucker\n",
      "true Fusing\n",
      "true Funk\n",
      "Fukah\n",
      "Fuken\n",
      "Foker\n",
      "Fukin\n",
      "g0k\n",
      "true gay\n",
      "gay boy\n",
      "gay girl\n",
      "true gays\n",
      "true gay\n",
      "God-damned\n",
      "h0r\n",
      "true hear\n",
      "true here\n",
      "true hells\n",
      "true hoar\n",
      "true door\n",
      "true Moore\n",
      "jack of\n",
      "true jape\n",
      "true japes\n",
      "true jerk-off\n",
      "jisim\n",
      "true miss\n",
      "Jim\n",
      "tiz\n",
      "true knob\n",
      "true knobs\n",
      "true knob\n",
      "true aunt\n",
      "true aunts\n",
      "kuntz\n",
      "true Lesbian\n",
      "Lezian\n",
      "Lip shits\n",
      "Lipschutz\n",
      "true masochist\n",
      "true masochist\n",
      "masterbait\n",
      "mastrbait\n",
      "true masturbate\n",
      "master baiter\n",
      "true masturbate\n",
      "true masturbates\n",
      "Motha Fucker\n",
      "Motha Fuker\n",
      "Motha Fukah\n",
      "Motha Fuker\n",
      "Mother Fucker\n",
      "Mother Fukah\n",
      "Mother Fuker\n",
      "Mother Fukah\n",
      "Mother Fuker\n",
      "mother-fucker\n",
      "Mutha Fucker\n",
      "Mutha Fukah\n",
      "Mutha Fuker\n",
      "Mutha Fukah\n",
      "Mutha Fuker\n",
      "n1gr\n",
      "true nasty\n",
      "true nigger\n",
      "nigur;\n",
      "niger;\n",
      "nigr;\n",
      "true oafish\n",
      "true orgasm\n",
      "true orgasm\n",
      "true orgasm\n",
      "true orifice\n",
      "true orifice\n",
      "true orifices\n",
      "true pack\n",
      "Mackie\n",
      "true pack\n",
      "paki\n",
      "pakie\n",
      "true pay\n",
      "true pecker\n",
      "true peens\n",
      "penus\n",
      "true peens\n",
      "peinus\n",
      "true pens\n",
      "true panes\n",
      "true penis\n",
      "penis-breath\n",
      "true pens\n",
      "penus\n",
      "true Pouch\n",
      "true Chuck\n",
      "Phuk\n",
      "true Pucker\n",
      "Plucker\n",
      "Colac\n",
      "true Pollack\n",
      "true polka\n",
      "Ponani\n",
      "true price\n",
      "true prick\n",
      "true prank\n",
      "true puss\n",
      "true pusses\n",
      "true pussy\n",
      "true puke\n",
      "true pucker\n",
      "true queer\n",
      "true queers\n",
      "true queer\n",
      "true queers\n",
      "qwerz\n",
      "true weir\n",
      "true rectum\n",
      "true rectum\n",
      "true retard\n",
      "true sadist\n",
      "true snack\n",
      "schlong\n",
      "true screwing\n",
      "true semen\n",
      "true sex\n",
      "true sexy\n",
      "true Shit\n",
      "true shit\n",
      "true shelter\n",
      "true shits\n",
      "true shatter\n",
      "sh1tz\n",
      "true shit\n",
      "true shits\n",
      "true hitter\n",
      "true Shitty\n",
      "true Shit\n",
      "true shit\n",
      "true Shy\n",
      "true Shute\n",
      "true Shitty\n",
      "true Shyly\n",
      "true askance\n",
      "true sank\n",
      "true spanker\n",
      "true spanker\n",
      "true spanks\n",
      "true Swanky\n",
      "true slut\n",
      "true sluts\n",
      "true Smutty\n",
      "true slut\n",
      "son-of-a-bitch\n",
      "true tit\n",
      "true turd\n",
      "va1jina\n",
      "true vagina\n",
      "true vagina\n",
      "true vagina\n",
      "true vagina\n",
      "true vagina\n",
      "true vulva\n",
      "true vulva\n",
      "true wop\n",
      "wh0r\n",
      "where\n",
      "true whore\n",
      "true rated\n",
      "true xxx\n",
      "b!+ch\n",
      "true bitch\n",
      "blow job\n",
      "true lit\n",
      "arschloch\n",
      "true fuck\n",
      "true shit\n",
      "true ass\n",
      "as hole\n",
      "true bitch\n",
      "b17ch\n",
      "true bitch\n",
      "true bastard\n",
      "true birch\n",
      "true violas\n",
      "true bucket\n",
      "true cock\n",
      "true caw\n",
      "true chink\n",
      "true pica\n",
      "true slits\n",
      "true cock\n",
      "true cum\n",
      "true cut\n",
      "true dildo\n",
      "dirsa\n",
      "true ejaculate\n",
      "fat as\n",
      "true fuck\n",
      "true funk\n",
      "fux0r\n",
      "hoer\n",
      "hoer\n",
      "true ism\n",
      "true gawk\n",
      "true glitch\n",
      "l3i+ch\n",
      "true lesbian\n",
      "true masturbate\n",
      "masterbat*\n",
      "masterbat3\n",
      "mother fucker\n",
      "s.o.b.\n",
      "true moo\n",
      "true Nazi\n",
      "true niggard\n",
      "true nigger\n",
      "nut sack\n",
      "true fuck\n",
      "true pimps\n",
      "true puss\n",
      "true pussy\n",
      "true scrotum\n",
      "true shit\n",
      "she male\n",
      "true shin\n",
      "true shun\n",
      "true slut\n",
      "true smut\n",
      "true tees\n",
      "true tits\n",
      "true boobs\n",
      "b0bs\n",
      "true tee\n",
      "testical\n",
      "true testicle\n",
      "true tit\n",
      "w0se\n",
      "jack of\n",
      "true wan\n",
      "true hoar\n",
      "true whore\n",
      "true damn\n",
      "true dyke\n",
      "true fuck\n",
      "*shit*\n",
      "@$$\n",
      "true ambit\n",
      "andskota\n",
      "arse*\n",
      "asramer\n",
      "true air\n",
      "true birch\n",
      "true bitch\n",
      "true bollocks\n",
      "true breasts\n",
      "but-pirate\n",
      "true carbon\n",
      "cazo\n",
      "true chroma\n",
      "true chug\n",
      "true Cock\n",
      "cunt*\n",
      "true damn\n",
      "day go\n",
      "true doge\n",
      "true dick\n",
      "true dike\n",
      "true pupa\n",
      "dziwka\n",
      "true ejaculate\n",
      "Ekrem*\n",
      "Elton\n",
      "true encumber\n",
      "true fen\n",
      "true fag\n",
      "fanculo\n",
      "true fanny\n",
      "true fees\n",
      "neg\n",
      "Melcher\n",
      "true sicken\n",
      "true fitter\n",
      "true Flicker\n",
      "true foreskin\n",
      "Fote\n",
      "Fu(*\n",
      "fuk*\n",
      "futkretzn\n",
      "true gay\n",
      "true goo\n",
      "true guinea\n",
      "her\n",
      "h4x0r\n",
      "true hell\n",
      "helvete\n",
      "hoer\n",
      "true honey\n",
      "true Hudson\n",
      "true hi\n",
      "Injune\n",
      "tiz\n",
      "kanker*\n",
      "true like\n",
      "klotzak\n",
      "true kraut\n",
      "true knuckle\n",
      "kuku\n",
      "kuksuger\n",
      "Kurac\n",
      "kurwa\n",
      "kusi*\n",
      "kyrpa*\n",
      "lesbo\n",
      "true manhood\n",
      "true masturbate\n",
      "merd*\n",
      "mi bun\n",
      "monkleigh\n",
      "mouliewop\n",
      "true muse\n",
      "mulku\n",
      "true muscle\n",
      "true Nazis\n",
      "nepesaurio\n",
      "true nigger\n",
      "orospu\n",
      "paska*\n",
      "true peruse\n",
      "true pica\n",
      "pierdol*\n",
      "true pillar\n",
      "true pommel\n",
      "true piss\n",
      "true pizza\n",
      "pontse\n",
      "true poop\n",
      "true porn\n",
      "true porn\n",
      "true prank\n",
      "pre-ten\n",
      "true hula\n",
      "true pule\n",
      "true put\n",
      "true put\n",
      "qahbeh\n",
      "true queer\n",
      "true Gutenberg\n",
      "true chaffer\n",
      "scheis*\n",
      "schlampe\n",
      "true schmuck\n",
      "true screw\n",
      "sh!t*\n",
      "sharmuta\n",
      "sharmute\n",
      "ship al\n",
      "true phiz\n",
      "skribz\n",
      "skurwysyn\n",
      "true sphincter\n",
      "true spic\n",
      "spierdalaj\n",
      "true splodge\n",
      "true skua\n",
      "b0b*\n",
      "true testicle\n",
      "true titter\n",
      "true tat\n",
      "vitu\n",
      "wank*\n",
      "true wetback\n",
      "wichser\n",
      "true wop\n",
      "yd\n",
      "true labour\n",
      "289\n",
      "458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encountebadwords([\"fuck\",\"shit\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exemple pour utiliser les fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y,X=readdata(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'imagin', u'e', u'e', u'sanction', u'e', u'forev', u'hear', u'ea', u'regul', u'e', u'hide', u'pretenc', u'friend', u'nuclear', u'energi', u'.', u'2', u'day', u'e', u'.', u'.', u'inspector', u'e', u'quit', u'kill', u'civilian', u'e', u'respect', u'border', u'right', u'neighbour', u'countri', u'e', u'e', u'e', u'shut', u'nuclear', u'plant', u'e', u'monitor', u'system', u'fanci', u'e', u'water', u'treatment', u'plant', u'earli', u'warn', u'sandstorm', u'system', u'traffic', u'light', u'major', u'citi', u'...', u'..(', u'inki', u'finger', u'lip', u'edg', u'e', u'teenag', u'revolt', u'toppl', u'regim', u'...', u'disconnect', u'...', u'facebok', u'....', u'buwhahjahahaha', u'.\"\"\"']\n",
      "[u'imagin', u'e', u'e', u'sanction', u'e', u'forev', u'hear', u'ea', u'regul', u'e', u'hide', u'pretenc', u'friend', u'nuclear', u'energi', u'.', u'2', u'day', u'e', u'.', u'.', u'inspector', u'e', u'quit', u'kill', u'civilian', u'e', u'respect', u'border', u'right', u'neighbour', u'countri', u'e', u'e', u'e', u'shut', u'nuclear', u'plant', u'e', u'monitor', u'system', u'fanci', u'e', u'water', u'treatment', u'plant', u'earli', u'warn', u'sandstorm', u'system', u'traffic', u'light', u'major', u'citi', u'...', u'..(', u'inki', u'finger', u'lip', u'edg', u'e', u'teenag', u'revolt', u'toppl', u'regim', u'...', u'disconnect', u'...', u'facebok', u'....', u'buwhahjahahaha', u'.\"\"\"']\n"
     ]
    }
   ],
   "source": [
    "# for i in range(0,len(X)):\n",
    "for i in range(0,2):\n",
    "    lines=removehtmltags(X[i])\n",
    "    line=removebadtoken(line)\n",
    "    lines=commentnormalizer(line)\n",
    "    lines=Tokenization(line) \n",
    "    lines=removestopwords(lines)\n",
    "    lines=repeatreplace(lines)\n",
    "    lines=commentcorrect(lines)\n",
    "    lines=commentStemmer(lines)\n",
    "    print lines\n",
    "\n",
    "\n",
    "#     print len(lines)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
