{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def selectJRandom(i, t):\n",
    "    # according to the alpha1 we should choose the second alpha, t is the number of alphas.\n",
    "    j = i\n",
    "    while (j == i):\n",
    "        j = int(np.random.uniform(0, t))\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import \n",
    "# SVM PAR SMO (Sequential Minimal Optimization)\n",
    "# Da JU\n",
    "# algotithme platt SMO reference Machine Learning in action \n",
    "class SVM_help:\n",
    "    def __init__(self, X, y, C, tol):\n",
    "        # initial\n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "        self.C = c\n",
    "        self.tol = tol\n",
    "        self.alphas = np.zeros((self.n, 1))\n",
    "        self.b = 0\n",
    "        self.cache = np.zeoros((self.n, 2)) # first col is flag, second col is the evalue\n",
    "        \n",
    "        def calcE(o,k):\n",
    "            fk = np.multiply(o.alphas, o.y).T.dot(o.X.dot(o.X[k,:].T)) + o.b\n",
    "            ek = fk - o.y[k]\n",
    "            return ek\n",
    "        \n",
    "        def selectJ(i ,o, ei):\n",
    "            k_max = -1\n",
    "            diffirence_e_max = 0\n",
    "            ej = 0\n",
    "            o.cache[i] = [1, ei]\n",
    "            validcache = np.nonzero(o.cache[:,0].A)[0]\n",
    "            if len(validcache) > 1:\n",
    "                for k in validcache:\n",
    "                    if k == i: continue\n",
    "                    ek = calcE(o, k)\n",
    "                    diffirencee = abs(ei - ek)\n",
    "                    if (diffirencee > diffirence_e_max):\n",
    "                        k_max = k\n",
    "                        diffirence_e_max = diffirencee\n",
    "                        ej = ek\n",
    "                return k_max, ej\n",
    "            else:\n",
    "                j = selectJRandom(i, o.n)\n",
    "                ej = calcE(o,j)\n",
    "            return j, ej\n",
    "        \n",
    "        def updatek(o,k):\n",
    "            ek = calcE(o, l)\n",
    "            o.cache[k] = [1,ek]\n",
    "            \n",
    "        \n",
    "        def clipAlpha(aj, H, L):\n",
    "            if aj > H:\n",
    "                aj = H\n",
    "            if L > aj:\n",
    "                aj = L\n",
    "            return aj  \n",
    "            \n",
    "        def innerLoop(i, o):\n",
    "            ei = calcE(o, i)\n",
    "            if ((o.y[i] * ei < -o.tol) and (o.alphas[i] * ei < -o.C)) or ((o.y[i]*ei > o.tol) and (o.alphas[i] > 0)):\n",
    "                j, ej = selectJ(i, o ,ei)\n",
    "                aplpha_I_old = o.alphas[i].copy()\n",
    "                aplpha_J_old = o.alphas[j].copy()\n",
    "                if (o.y[i] != o.y[j]):\n",
    "                    L = max(0, o.alphas[j] - o.alphas[i])\n",
    "                    H = min(o.C, o.C + o.alphas[j] - o.alphas[i])\n",
    "                else:\n",
    "                    L = max(0, o.alphas[j] + o.alphas[i] - C)\n",
    "                    H = min(o.C, o.alphas[j] + o.alphas[i])\n",
    "                if L==H: \n",
    "                    return 0\n",
    "                eta = 2.0 * o.X[i,:]*o.X[j,:].T - o.X[i,:]*o.X[i,:].T - o.X[j,:]*o.X[j,:].T\n",
    "                if eta >= 0: print \"eta>=0\"; continue\n",
    "                o.alphas[j] = o.alphas[j] - o.y[j]*(ei - ej)/eta\n",
    "                o.alphas[j] = clipAlpha(o.alphas[j],H,L)\n",
    "                updatek(o,j)\n",
    "                if (o.abs(o.alphas[j] - aplpha_J_old) < o.tol):\n",
    "                    return 0\n",
    "                o.alphas[i] = o.alphas[i] + o.y[j] * o.y[i]*(aplpha_J_old - o.alphas[j])\n",
    "                updatek(o, i)\n",
    "                b1 = o.b - ei- o.y[i]*(o.alphas[i]-aplpha_I_old)*dataMatrix[i,:]*dataMatrix[i,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[i,:]*dataMatrix[j,:].T\n",
    "                b2 = b - ej- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[j,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[j,:]*dataMatrix[j,:].T\n",
    "                if (0 < alphas[i]) and (C > alphas[i]): b = b1\n",
    "                elif (0 < alphas[j]) and (C > alphas[j]): b = b2\n",
    "\n",
    "                    \n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "                        \n",
    "                    \n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
