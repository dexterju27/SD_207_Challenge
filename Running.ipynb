{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = []\n",
    "y = []\n",
    "with open('train.csv') as f:\n",
    "    for line in f:\n",
    "        y.append(int(line[0]))\n",
    "        X.append(line[5:-6])\n",
    "y = np.array(y)\n",
    "\n",
    "import io\n",
    "def loadDataSet(test_fileName, train_fileName):\n",
    "    test = []\n",
    "    train = []\n",
    "    with io.open(test_fileName, encoding = 'utf-8') as f:\n",
    "        for line in f:\n",
    "            lineArr = line.strip().split('\\t')\n",
    "            test.append(lineArr)\n",
    "    with io.open(train_fileName, encoding = 'utf-8') as f:\n",
    "        for line in f:\n",
    "            lineArr = line.strip().split('\\t')\n",
    "            train.append(lineArr)\n",
    "    return test,train\n",
    "test, train = loadDataSet('X_test.txt', 'X_train.txt')\n",
    "\n",
    "def words2Vectors(wordList, data):\n",
    "    vec = [0] * len(wordList)\n",
    "    for word in data:\n",
    "        if word in wordList:\n",
    "            vec[wordList.index(word)] = vec[wordList.index(word)] + 1 # + (word in badList) \n",
    "            # count bad words twice\n",
    "    return vec\n",
    "\n",
    "def createWordList(X, minchar):\n",
    "    wordContent = []\n",
    "    wordCount = dict()\n",
    "    for line in X:\n",
    "        for word in line:\n",
    "            if len(word) > minchar:\n",
    "                if word not in wordCount.keys():\n",
    "                    wordCount[word] = 1 # + (word in badList)\n",
    "            else:\n",
    "                continue\n",
    "    return wordCount.keys(), wordCount\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordList, c = createWordList(train, 2)\n",
    "vectors_train = []\n",
    "for x in train:\n",
    "    vectors_train.append(words2Vectors(wordList, x))\n",
    "vectors_test = []\n",
    "for x in test:\n",
    "    vectors_test.append(words2Vectors(wordList, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on calcule \n",
    "def proximal_l1(w, lam,rho):\n",
    "    result = []\n",
    "    lam = rho * lam\n",
    "    for wi in w:\n",
    "        if wi > lam:\n",
    "            result.append(wi - lam)\n",
    "        elif np.abs(wi) <= lam:\n",
    "            result.append(0)\n",
    "        else :\n",
    "            result.append(wi + lam)\n",
    "    return result\n",
    "\n",
    "def function_f(w, X, Y, rho):\n",
    "    X = np.c_[X, np.ones(X.shape[0])] # Add one cols\n",
    "    sum_f = 0\n",
    "    k = 0\n",
    "    for xi, yi in zip(X, y):\n",
    "        exp = np.exp(-1. * yi * xi.T.dot(w))\n",
    "        sum_f = sum_f + np.log1p(exp) \n",
    "    sum_f = sum_f / y.shape[0]\n",
    "    return sum_f \n",
    "\n",
    "# get value w (30,0) \n",
    "def grandient_f(w, X, Y, rho):\n",
    "    X = np.c_[X, np.ones(X.shape[0])] # Add one cols\n",
    "    sum_gradient = np.zeros(X.shape[1])\n",
    "    for xi, yi in zip(X, Y):\n",
    "        exp = np.exp(-1. * yi * xi.T.dot(w))\n",
    "        sum_gradient = sum_gradient + xi* (-1.* yi) * (1. - (1. / (1. + exp)))   \n",
    "    sum_gradient = sum_gradient / y.shape[0]\n",
    "    return sum_gradient \n",
    "# return value of g is (31,) h is (31, 31)\n",
    "\n",
    "# question 2.2\n",
    "def optimisation_proximal(X,y,function_f, grandient_f, proximal_l1, rho,x0, rtol, maxloop, lam, beta):\n",
    "    xk = x0\n",
    "    fk_old = np.inf\n",
    "    k = 0\n",
    "\n",
    "    fk, grad_fk = function_f(xk, X, y, rho), grandient_f(xk,X,y,rho)\n",
    "    while True :\n",
    "        k = k + 1\n",
    "        grad_fk = grandient_f(xk,X,y,rho)\n",
    "        while True:  #lam change\n",
    "            xk_grad = xk - lam * grad_fk\n",
    "            prx = proximal_l1(xk_grad, lam, rho)\n",
    "            Gt = (xk - prx) / lam\n",
    "            lhand = function_f(xk - lam * Gt, X,y,rho)\n",
    "            rhand = fk - lam * grad_fk.dot(Gt) + (0.5 * lam) * Gt.dot(Gt)\n",
    "            if lhand <= rhand:\n",
    "                break\n",
    "            else:\n",
    "                lam *= beta\n",
    "\n",
    "        xk -= lam * Gt\n",
    "        fk_old = fk\n",
    "        fk, grad_fk = function_f(xk,X,y,rho), grandient_f(xk,X,y,rho)\n",
    "        if np.linalg.norm(lam * np.array(proximal_l1(xk,lam,rho)) - np.zeros(xk.shape[0])) < rtol or k > maxloop: # stop condition\n",
    "            print fk\n",
    "            return xk\n",
    "        \n",
    "        \n",
    "        \n",
    "class Regression_logstic():\n",
    "    def __init__(self,C = 1. ,rtol = 10**-10, maxloop=1000, lam=0.5, beta = 0.5):\n",
    "        # initial\n",
    "        self.rtol = rtol\n",
    "        self.maxloop = maxloop\n",
    "        self.lam = lam\n",
    "        self.beta = beta\n",
    "        self.rho = 1. / C\n",
    "        # first col is flag, second col is the evalue\n",
    "    def get_params(self, deep=True):\n",
    "        return \"c: +\" + str(self.C) + str(self.tol)\n",
    "    def fit(self, X, y):\n",
    "        self.rho = 1./ y.shape[0]\n",
    "        self.w = np.zeros(features.shape[1] + 1)\n",
    "        self.w = optimisation_proximal(X, y, function_f, grandient_f, proximal_l1, self.rho,self.w , self.rtol ,self.maxloop,  self.lam, self.beta)  \n",
    "        print  self.rho\n",
    "    def predict(self, X):\n",
    "        X = np.c_[X, np.ones(X.shape[0])] # Add one cols\n",
    "        result = X.dot(self.w)\n",
    "        result[result >0 ] = 1\n",
    "        result[result < 0] = 0\n",
    "        return result.astype('int').tolist()\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y[y == 0] = -1.\n",
    "from sklearn.feature_selection import chi2,SelectKBest\n",
    "select = SelectKBest(chi2, 3000)\n",
    "features = select.fit_transform(vectors_train, y)\n",
    "features_test = select.transform(vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.438556555543\n",
      "0.000226500566251\n"
     ]
    }
   ],
   "source": [
    "clf = Regression_logstic( )\n",
    "clf.fit(features, y)\n",
    "result = clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('y_pred_3000_feature_774807430902.txt', result, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "train_after_tfidf = tf_transformer.fit_transform(features,y)\n",
    "test_after_tfidf = tf_transformer.transform(features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.51661051189\n",
      "0.000226500566251\n"
     ]
    }
   ],
   "source": [
    "clf = Regression_logstic()\n",
    "clf.fit(train_after_tfidf.toarray(), y)\n",
    "result = clf.predict(test_after_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('y_pred_c_1.txt', result, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
